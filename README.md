# Travaux Pratiques de Machine Learning - ESPRIT 2020/2021

Ce repository contient une collection complète des travaux pratiques (TP) que j'ai réalisés durant le cours de Machine Learning à ESPRIT pendant l'année académique 2020-2021. Chaque TP couvre un aspect clé des algorithmes de Machine Learning, avec des exemples de code, des explications théoriques et une analyse des résultats.

## Support Vector Machines (SVM)
Dans ce TP, nous avons mis en œuvre l'algorithme des machines à vecteurs de support, utilisé principalement pour la classification linéaire et non linéaire. Nous avons exploré différentes fonctions de noyau (linéaire, polynomial, gaussien) et ajusté les hyperparamètres pour optimiser la performance du modèle.

## Arbres de Décision
Ce TP porte sur la construction et l'évaluation des arbres de décision, un algorithme simple mais puissant pour la classification. Nous avons appris à utiliser des critères tels que l'entropie et le Gini pour créer des branches et élaguer l'arbre afin d'améliorer la généralisation du modèle.

## Analyse en Composantes Principales (ACP)
L'ACP est un algorithme de réduction de dimension qui permet de simplifier les données tout en conservant les informations les plus importantes. Ce TP s'est concentré sur la visualisation des données dans des espaces de dimension réduite et sur l'amélioration de la performance des modèles en réduisant la complexité.

## Régression Linéaire
Dans ce TP, nous avons abordé la régression linéaire, un algorithme de base pour les tâches de prédiction continue. Le TP couvre la construction d'un modèle de régression, l'interprétation des coefficients, ainsi que l'évaluation de la performance à l'aide d'indicateurs tels que le R² et l'erreur quadratique moyenne.

## k-Nearest Neighbors (KNN)
Ce TP se concentre sur l'algorithme des k-plus proches voisins, un algorithme de classification basé sur la similarité des instances. Nous avons implémenté KNN pour résoudre des problèmes de classification tout en ajustant des paramètres comme la valeur de **k** et la distance utilisée (euclidienne, manhattan).

## k-Means & Classification Ascendante Hiérarchique (CAH)
Dans ce TP, nous avons étudié deux algorithmes de clustering : k-Means, un algorithme de partitionnement non supervisé, et la Classification Ascendante Hiérarchique (CAH), qui génère un dendrogramme représentant les regroupements des données. Ces deux techniques permettent de segmenter des jeux de données non étiquetés en groupes homogènes.

## Atelier de Préparation des Données
Ce TP est consacré à la préparation des données, une étape essentielle dans tout projet de Machine Learning. Nous avons abordé des techniques de nettoyage des données, de gestion des valeurs manquantes, de normalisation, de création de variables, et de transformation pour améliorer la qualité des données avant de les introduire dans un modèle.
